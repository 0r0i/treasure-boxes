_export:
  !include : config/params.yml
  td:
    database: ${dbname}
    engine: hive

+preparation:
  call>: common/prepare.dig

# Train with pre-trained model on TensorFlow Hub and store prediction results to TD
+train:
  py>: predict_chainer.predict_chainer
  database: ${dbname}
  input_table: "movie_review_test_shuffled"
  output_table: "test_predicted_polarities_chainer"
  docker:
    # Note: This image is temporary. It might change in the near future.
    image: 'digdag/digdag-python:3.7.3-stretch'
  _env:
    TD_API_KEY: ${secret:apikey}
    TD_API_SERVER: ${secret:endpoint}
    # This is a temporal workaround for Spark. This should be removed in future.
    SPARK_LOCAL_IP: "127.0.0.1"
